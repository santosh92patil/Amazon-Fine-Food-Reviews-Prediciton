{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Jr4cugH3mZ_X"
   },
   "outputs": [],
   "source": [
    "# Credits: https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "# LSTM for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AvbD4hyhIv7d",
    "outputId": "538dd356-bd2c-4999-c9b5-27bc7832e8ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3O79pLVUJ0iF"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/content/gdrive/My Drive/Colab Notebooks/reviews_amzn.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "e0YEXZGeJ9j3",
    "outputId": "a977a8de-a91b-4c9e-b8da-27b586c5a62e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  y\n",
      "0   witti littl book make son laugh loud recit ca...  1\n",
      "1   rememb see show air televis year ago child si...  1\n",
      "2   beetlejuic well written movi everyth excel ac...  1\n",
      "3   twist rumplestiskin captur film star michael ...  1\n",
      "4   beetlejuic excel funni movi keaton hilari wac...  1\n",
      "(50000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3Z9GV_8bIx__"
   },
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VvqtirPGLm_p"
   },
   "outputs": [],
   "source": [
    "final_X = data['text']\n",
    "final_y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yTpR0MxhLtuc"
   },
   "outputs": [],
   "source": [
    "X_train = final_X[:40000]\n",
    "X_test = final_X[40000:]\n",
    "y_train = final_y[:40000]\n",
    "y_test = final_y[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "QhcllGs6Wajk"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7sj7rRUWYEau"
   },
   "outputs": [],
   "source": [
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "eYEE6ts7GAjC",
    "outputId": "bbdd378f-06e8-481b-9cca-41f57f22223b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 1, 150, 14, 100, 442, 1403, 23, 130, 17, 331, 244, 46, 522, 26, 220, 6, 351]\n",
      "<class 'list'>\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(X_train[45])\n",
    "print(type(X_train[45]))\n",
    "print(len(X_train[45]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "colab_type": "code",
    "id": "57N6TyKLH-Pc",
    "outputId": "c896100d-22ed-4ab5-971e-48a8434e6905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 500)\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0   11    1  150   14  100  442 1403   23\n",
      "  130   17  331  244   46  522   26  220    6  351]\n"
     ]
    }
   ],
   "source": [
    "# truncate and/or pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "CquzlqrOIYGn",
    "outputId": "7730480f-7fdf-4e2f-d80b-832a4b981177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "#Refer: https://datascience.stackexchange.com/questions/10615/number-of-parameters-in-an-lstm-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "colab_type": "code",
    "id": "A_FT0dPNIeLP",
    "outputId": "72859a39-17a1-410a-fa1c-9c2826bd0a51"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "40000/40000 [==============================] - 912s 23ms/step - loss: 0.3622 - acc: 0.8395\n",
      "Epoch 2/5\n",
      "40000/40000 [==============================] - 907s 23ms/step - loss: 0.2543 - acc: 0.9000\n",
      "Epoch 3/5\n",
      "40000/40000 [==============================] - 910s 23ms/step - loss: 0.2238 - acc: 0.9141\n",
      "Epoch 4/5\n",
      "40000/40000 [==============================] - 904s 23ms/step - loss: 0.1980 - acc: 0.9247\n",
      "Epoch 5/5\n",
      "40000/40000 [==============================] - 887s 22ms/step - loss: 0.1800 - acc: 0.9329\n",
      "Accuracy: 87.82%\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, nb_epoch=5, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TGylBGVGqWze"
   },
   "source": [
    "<h2> Model 2 (Two Lstm layers ) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "_ekCzRkKqVqX",
    "outputId": "7b5ff889-50a6-4e35-c1c5-95fd55dfbd57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 500, 100)          53200     \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 293,701\n",
      "Trainable params: 293,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vecor_length = 32\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(5000, embedding_vecor_length, input_length=max_review_length))\n",
    "model1.add(LSTM(100, return_sequences=True))\n",
    "model1.add(LSTM(100))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "K0ZxWAzYrpLE",
    "outputId": "ec17e002-64b3-4dd2-ff8d-217e4634e8d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 1795s 45ms/step - loss: 0.3593 - acc: 0.8402\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 1843s 46ms/step - loss: 0.2526 - acc: 0.9000\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 1841s 46ms/step - loss: 0.2231 - acc: 0.9139\n",
      "Accuracy: 88.23%\n"
     ]
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, nb_epoch=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model1.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G3dElqPCEF1g"
   },
   "source": [
    "<h1>Summary</h1>\n",
    "\n",
    "1.   Model1 with one LSTM layer ran for 5 epochs go1 accuracy of 87.81\n",
    "2.   Model2 with 2 LSTM layers ran for 3 epochs got accuracy of 88.23\n",
    "3.   We can get high accuracies if we run for more epochs. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "67q5ZN7dEt7t"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_Amazon_Food_Reviews.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
