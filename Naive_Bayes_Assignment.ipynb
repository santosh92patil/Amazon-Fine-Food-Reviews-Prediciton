{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "cca803b6d97425ba2a13c6d6e72f10ff43c8f189",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'Reviews.csv'\n",
    "df = pd.read_csv(path)\n",
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "581e00e57ffdee654ae5aaa69edea410ecea7b96",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removing Neural reviews\n",
    "data_s = data[data['Score']!=3]\n",
    "\n",
    "#Updating Score to 0 or 1\n",
    "def partition(x):\n",
    "    if x<3:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "score_upd = data_s['Score']\n",
    "temp = score_upd.map(partition)\n",
    "data_s['Score'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "b521b17128001f49e1c5c912508ce8a68d89e61f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_data = data_s.drop_duplicates(subset=('UserId','ProfileName','Time','Text'))\n",
    "final = final_data[final_data['HelpfulnessNumerator']<=final_data['HelpfulnessDenominator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = final.head(250000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "5be477ccc70c1734f253dda640d3a22aee410b2b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = final.sort_values(['Time'], axis=0)   #TIme based sorting\n",
    "\n",
    "final_X = final['Text']\n",
    "final_y = final['Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff3f2e4c85e9c202711219f9066eaf6c690ab006"
   },
   "source": [
    "**Data preprocessing**\n",
    "* stopword\n",
    "* stemming\n",
    "* Punctuations\n",
    "removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "91db837a04e5476065ec24c73f867b575079a99e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00 %\r"
     ]
    }
   ],
   "source": [
    "import re\n",
    "temp_1 =[]\n",
    "snow = nltk.stem.SnowballStemmer('english')\n",
    "i = 0\n",
    "N = len(final_X)\n",
    "for sentence in final_X:\n",
    "    sentence = sentence.lower()\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    sentence = re.sub(cleanr, ' ', sentence)        #Removing HTML tags\n",
    "    sentence = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    sentence = re.sub(r'[.|,|)|(|\\|/]',r' ',sentence)        #Removing Punctuations\n",
    "    \n",
    "    words = [snow.stem(word) for word in sentence.split() if word not in stopwords.words('english')]\n",
    "    temp_1.append(words)\n",
    "    print(\"{0:.2f} %\".format((i/N)*100),end ='\\r')\n",
    "    i = i+1\n",
    "    \n",
    "final_X = temp_1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "d26df03ede047fbcc021786199b609b2968d12ec",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = []\n",
    "for row in final_X:\n",
    "    seq = ''\n",
    "    for word in row:\n",
    "        seq = seq + ' ' + word\n",
    "    sent.append(seq)\n",
    "\n",
    "final_X = sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "503fbc3e525dd9750034cc0f23d91d1f7bb05308",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting data into train and test\n",
    "#Splitting data into train and test\n",
    "X_train = final_X[:175000]\n",
    "X_test = final_X[175000:]\n",
    "y_train = final_y[:175000]\n",
    "y_test = final_y[175000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b7c48ef4bdb975352cc8a02222af4bb6ecb795a1"
   },
   "source": [
    "**Naive Bayes on BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "0bd42c09295f383013c1f476c4896aba41d234fb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bag of Words\n",
    "\n",
    "count_vect = CountVectorizer(max_features = 5000)\n",
    "bow_X_train = count_vect.fit_transform(X_train)\n",
    "bow_X_test = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "cc17d545e49171c54007c4004460ba08db8fead6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha =  {'alpha': 0.1}\n",
      "Accuracy on train data =  89.82685714285714\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.01,0.1,1,10,100]\n",
    "clf = MultinomialNB()\n",
    "param_grid = { 'alpha':alphas}\n",
    "grid = GridSearchCV(estimator = clf,param_grid=param_grid ,cv = 5,n_jobs = -1)\n",
    "grid.fit(bow_X_train, y_train)\n",
    "print(\"best alpha = \", grid.best_params_)\n",
    "print(\"Accuracy on train data = \", grid.best_score_*100)\n",
    "t_acc1 = grid.best_score_*100\n",
    "a = grid.best_params_\n",
    "optimal_a1 = a.get('alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "6b724e65c9d5662ec5ea0c7102db1e8ae61b76d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy=88.961333%\n",
      "\n",
      "precision=94.044722%\n",
      "\n",
      "recall=92.471102%\n",
      "\n",
      "F1-Score=93.251274%\n",
      "\n",
      " [[ 9523  3622]\n",
      " [ 4657 57198]]\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha = optimal_a1)\n",
    "\n",
    "clf.fit(bow_X_train,y_train)\n",
    "\n",
    "pred = clf.predict(bow_X_test)\n",
    "\n",
    "acc1 = accuracy_score(y_test, pred) * 100\n",
    "pre1 = precision_score(y_test, pred) * 100\n",
    "rec1 = recall_score(y_test, pred) * 100\n",
    "f11 = f1_score(y_test, pred) * 100\n",
    "\n",
    "print('\\nAccuracy=%f%%' % (acc1))\n",
    "print('\\nprecision=%f%%' % (pre1))\n",
    "print('\\nrecall=%f%%' % (rec1))\n",
    "print('\\nF1-Score=%f%%' % (f11))\n",
    "\n",
    "cm = confusion_matrix(y_test,pred)\n",
    "print(\"\\n\",cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "3e31f57e5526c1996c9d756a7a42d27952cb0fcc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_log = list(map(abs,clf.feature_log_prob_))[0].argsort()[0:10]\n",
    "positive_log = list(map(abs,clf.feature_log_prob_))[1].argsort()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "1461eddf88ad1109df82a5a388c1f6db0fb70028"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of most negative impacting words =  [4380 2587 3448 3094 1758 4587 4927  964 1977 4707]\n",
      "Indices of most negative impacting words =  [2587 4380 1977 1758 2643 2021 4707 3094 3448 4587]\n"
     ]
    }
   ],
   "source": [
    "print(\"Indices of most negative impacting words = \", negative_log)\n",
    "print(\"Indices of most negative impacting words = \", positive_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "84e5545b9d03603b7623bfead6e21d5dc52e1084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positve impacting words\n",
      "like\n",
      "tast\n",
      "good\n",
      "flavor\n",
      "love\n",
      "great\n",
      "use\n",
      "one\n",
      "product\n",
      "tri\n"
     ]
    }
   ],
   "source": [
    "print(\"Positve impacting words\")\n",
    "for index in positive_log:\n",
    "    for i in count_vect.vocabulary_:\n",
    "        if count_vect.vocabulary_[i] == index:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "ff6467af359aec3e9c57b01a636ef92eefef7770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative impacting words\n",
      "tast\n",
      "like\n",
      "product\n",
      "one\n",
      "flavor\n",
      "tri\n",
      "would\n",
      "coffe\n",
      "good\n",
      "use\n"
     ]
    }
   ],
   "source": [
    "print(\"negative impacting words\")\n",
    "for index in negative_log:\n",
    "    for i in count_vect.vocabulary_:\n",
    "        if count_vect.vocabulary_[i] == index:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes on Tf-Idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "ead2ae2a35c1d42f2b532d5abde7ecabc1e4fb43",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(max_features=5000)\n",
    "tf_X_train = tf_idf.fit_transform(X_train)\n",
    "tf_X_test = tf_idf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "000188938ea0c295208fb84e2b8ccbde806ceded"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha =  {'alpha': 0.01}\n",
      "Accuracy on train data =  87.88685714285714\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.01,0.1,1,10,100]\n",
    "clf = MultinomialNB()\n",
    "param_grid = { 'alpha':alphas}\n",
    "grid = GridSearchCV(estimator = clf,param_grid=param_grid ,cv = 5,n_jobs = -1)\n",
    "grid.fit(tf_X_train, y_train)\n",
    "print(\"best alpha = \", grid.best_params_)\n",
    "print(\"Accuracy on train data = \", grid.best_score_*100)\n",
    "t_acc2 = grid.best_score_*100\n",
    "a = grid.best_params_\n",
    "optimal_a2 = a.get('alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "395c7ea2a8b803ad1016f4d7c184d62d46d35932"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy=88.969333%\n",
      "\n",
      "precision=94.048206%\n",
      "\n",
      "recall=92.477569%\n",
      "\n",
      "F1-Score=93.256275%\n",
      "\n",
      " [[ 9525  3620]\n",
      " [ 4653 57202]]\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha = optimal_a2)\n",
    "\n",
    "clf.fit(bow_X_train,y_train)\n",
    "\n",
    "pred = clf.predict(bow_X_test)\n",
    "\n",
    "acc2 = accuracy_score(y_test, pred) * 100\n",
    "pre2 = precision_score(y_test, pred) * 100\n",
    "rec2 = recall_score(y_test, pred) * 100\n",
    "f12 = f1_score(y_test, pred) * 100\n",
    "\n",
    "print('\\nAccuracy=%f%%' % (acc2))\n",
    "print('\\nprecision=%f%%' % (pre2))\n",
    "print('\\nrecall=%f%%' % (rec2))\n",
    "print('\\nF1-Score=%f%%' % (f12))\n",
    "\n",
    "cm = confusion_matrix(y_test,pred)\n",
    "print(\"\\n\",cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "d6c467bef97e7b1a8dd86f393662e4faf182992b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_log = list(map(abs,clf.feature_log_prob_))[0].argsort()[0:10]\n",
    "positive_log = list(map(abs,clf.feature_log_prob_))[1].argsort()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "fac6f18d4b385f773e10a322e57ecbef255c71e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positve impacting words\n",
      "like\n",
      "tast\n",
      "good\n",
      "flavor\n",
      "love\n",
      "great\n",
      "use\n",
      "one\n",
      "product\n",
      "tri\n"
     ]
    }
   ],
   "source": [
    "print(\"Positve impacting words\")\n",
    "for index in positive_log:\n",
    "    for i in tf_idf.vocabulary_:\n",
    "        if tf_idf.vocabulary_[i] == index:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "a5bdb06a916e776cfde79b59629f043434f88e2f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative impacting words\n",
      "tast\n",
      "like\n",
      "product\n",
      "one\n",
      "flavor\n",
      "tri\n",
      "would\n",
      "coffe\n",
      "good\n",
      "use\n"
     ]
    }
   ],
   "source": [
    "print(\"Negative impacting words\")\n",
    "for index in negative_log:\n",
    "    for i in tf_idf.vocabulary_:\n",
    "        if tf_idf.vocabulary_[i] == index:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Metrics using PrettyTable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+--------------+----------------+-------------+---------------+--------------+-----------+-------------+\n",
      "|    Model     | Alpha | Train_Acc(%) | Train_Error(%) | Test_Acc(%) | Test_Error(%) | Precision(%) | Recall(%) | F1-Score(%) |\n",
      "+--------------+-------+--------------+----------------+-------------+---------------+--------------+-----------+-------------+\n",
      "|  NB on BoW   |  0.1  |    89.83     |     10.17      |    88.96    |     11.04     |    94.04     |   92.47   |    93.25    |\n",
      "| NB on Tf-Idf |  0.01 |    87.89     |     12.11      |    88.97    |     11.03     |    94.05     |   92.48   |    93.26    |\n",
      "+--------------+-------+--------------+----------------+-------------+---------------+--------------+-----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "x = PrettyTable()\n",
    "\n",
    "model_1 = 'NB on BoW'\n",
    "model_2 = 'NB on Tf-Idf'\n",
    "x.field_names = [\"Model\",\"Alpha\",\"Train_Acc(%)\",\"Train_Error(%)\",\"Test_Acc(%)\",\"Test_Error(%)\",\"Precision(%)\",\"Recall(%)\",\"F1-Score(%)\"]\n",
    "\n",
    "t_acc1 = np.around(t_acc1, decimals = 2)\n",
    "t_err1 = np.around(100-t_acc1, decimals = 2)\n",
    "acc1 = np.around(acc1, decimals = 2)\n",
    "err1 = np.around(100-acc1, decimals = 2) \n",
    "pre1 = np.around(pre1, decimals = 2)\n",
    "rec1 = np.around(rec1, decimals = 2)\n",
    "f11 = np.around(f11, decimals = 2)\n",
    "\n",
    "t_acc2 = np.around(t_acc2, decimals = 2)\n",
    "t_err2 = np.around(100-t_acc2, decimals = 2)\n",
    "acc2 = np.around(acc2, decimals = 2)\n",
    "err2 = np.around(100-acc2, decimals = 2) \n",
    "pre2 = np.around(pre2, decimals = 2)\n",
    "rec2 = np.around(rec2, decimals = 2)\n",
    "f12 = np.around(f12, decimals = 2)\n",
    "\n",
    "x.add_row([model_1,optimal_a1,t_acc1,t_err1,acc1,err1,pre1,rec1,f11])\n",
    "x.add_row([model_2,optimal_a2,t_acc2,t_err2,acc2,err2,pre2,rec2,f12])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Observations\n",
    "\n",
    "* Considered 250k data used TIME BASED SPLITIING\n",
    "* Time based splitting done with the ratio as 70:30 = train:test\n",
    "* In BoW model , got alpha= 0.1 and In Tf-Idf model alpha = 0.01.\n",
    "* Used PrettyTable to make a table of all metrics for both models\n",
    "* But if I see the both Positive and negative words that impact our model, both seems semantically similar, because those are the words that repeat most both classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
